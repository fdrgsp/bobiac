{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee0331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The `ndv` package is not yet supported in Colab. Most of the `ndv` lines are commented out.\n",
    "# The `matplotlib` package can be used instead (already included in the pip list)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a60488",
   "metadata": {},
   "source": [
    "# Classical Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f33553a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install matplotlib\n",
    "# %pip install \"ndv[jupyter,vispy]\"\n",
    "%pip install numpy\n",
    "%pip install scikit-image\n",
    "%pip install scipy\n",
    "%pip install tifffile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab370b9",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook covers the following steps in building a **classic segmentation pipeline**:\n",
    "\n",
    "| Step | Concept | Why it matters |\n",
    "|---------|---------|----------------|\n",
    "| 0 | Setup | Import dependencies |\n",
    "| 1 | Loading an Image | Open tif image and display it |\n",
    "| 2 | Filtering | Learn how to filter images to improve thresholding results |\n",
    "| 3 | Thresholding | Learn how to use thresholding to generate a binary mask |\n",
    "| 4 | Labeling | Learn how to label binary masks |\n",
    "| 5 | Mask Refinement | Learn how to use apply mathematical operations to refine binary masks |\n",
    "| 6 | Processing Many Images | Learn how to apply processing steps to many images |\n",
    "\n",
    "\n",
    "Each chapter has:\n",
    "\n",
    "1. **Summary** – review core concepts from lecture.\n",
    "2. ✍️ **Exercise** – _your turn_ to write code!\n",
    "\n",
    "In this exercise, we will use the <a href=\"https://drive.google.com/uc?export=download&id=1Svlnr2R5CYf5NvRzx3FxghrrxdfnPdiY\"> <i class=\"fas fa-download\"></i> DAPI dataset </a> containing images of DAPI-stained nuclei."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c41893",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaf93b8",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd7d03",
   "metadata": {},
   "source": [
    "### Concept\n",
    "\n",
    "We are going to be using existing Python libraries in this lesson, so we need to specify them at the beginning of our code. This is called specifying our **dependencies**. It's standard practice to specify all dependencies at the very beginning of your code.\n",
    "\n",
    "For learning purposes, we will import everything here step by step, as it is introduced in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Specify dependencies and run the code block for each section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68d79a7a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf30588",
   "metadata": {},
   "source": [
    "## 1. Loading an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5317c0e",
   "metadata": {},
   "source": [
    "### Concept\n",
    "\n",
    "To work with an image in Python, we need to specify where the image file is so that we can **read**, or load, it. Once the image file is read, we can **view** it and process it.  \n",
    "\n",
    "### Specifying your file's path\n",
    "Once you have found your file's path, you should assign it to a variable to make it easy to work with. Here's an example:\n",
    "```python\n",
    "file_path = '/Users/edelase/Desktop/projects/bobiac/lectures/classic_segmentation/img.tif'\n",
    "```\n",
    "\n",
    "<p class=\"alert alert-warning\">\n",
    "    <strong>Caution:</strong> Be wary of spaces in folder names, as they sometimes cause terminal to add <b>\\</b> or <b>/</b> to file directories where they should not be. It is best practice to always use <b>_</b> in folder names whenever you would have wanted to have a space.\n",
    "</p>\n",
    "\n",
    "<p class=\"alert alert-info\">\n",
    "    <strong>Note:</strong> Specifying file paths is a common task outside of image segmentation with Python, so some of you may have experience with this already. Note the terminology though. An individual file's location is a <b> path</b>. A folder's path containing an individual or multiple files is called a <b>directory</b>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2962de",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Specify your image file's path and assign it to the variable `image_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2b64c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61607421",
   "metadata": {},
   "source": [
    "### Loading an image\n",
    "There are many different ways to read image files in Python. In this lesson, we will use the Python library `tifffile`, to read .tif image files. We will need to import `tifffile` in Setup. We should also import `numpy` to take advantage of accessing np.array tools you have learned about in the previous lesson.\n",
    "\n",
    "| Name | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "| `tifffile` | Reads and stores tiff files as np.arrays | `import tifffile` | [tifffile](https://pypi.org/project/tifffile//) |\n",
    "| `numpy` | Scientific computing package that contains np.arrays | `import numpy as np` | [numpy](https://numpy.org) |\n",
    "\n",
    "In order to read an image with `tifffile`, we will need to import it, and then provide it with the image's path. We will also import `numpy` too, although it is not necessary for `tifffile` to load the image.\n",
    "```python\n",
    "import tifffile # put in Setup\n",
    "import numpy as np # put in Setup\n",
    "raw_image = tifffile.imread(image_path)\n",
    "```\n",
    "`tifffile.imread()` will use that `image_path` you inputted to find your file and read it. It will then return the read file. Since we will be wanting to work with this file, we assign it to the variable `raw_image` for easy reference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14084981",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Use `tifffile` to read the image and assign it to the variable `raw_image`. Then, print its shape and dtype \n",
    "Remember to add your imports to Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752d458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04aa693c20bd460494e518b8cb84ef11",
   "metadata": {},
   "source": [
    "<p class=\"alert alert-info\">\n",
    "    <strong>Note:</strong> When we print this image's dtype, we see that it is <b>uint32</b>, or 32 bit. This is because the images we will be working with in this lesson did not come straight from the microscope. Before providing them to you, we applied some background correction steps including <b>flat-field correction</b> and <b>background subtraction</b>. You will learn about background subtraction in a future lesson.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae4186f",
   "metadata": {},
   "source": [
    "### Viewing the image\n",
    "In Python, reading the image and viewing it are two separate actions. Now that we have read the image and assigned it to the variable `raw_image`, we can view it using `ndv`, which we will need to import in Setup. \n",
    "\n",
    "| Name | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "| `ndv` | Multi-dimensional image viewer | `import ndv` | [ndv](https://pypi.org/project/ndv/) |\n",
    "\n",
    "We can use ndv to view `raw_image` as follows: \n",
    "```python\n",
    "import ndv # put in Setup\n",
    "ndv.imshow(raw_image)\n",
    "```\n",
    "`ndv.imshow()` will use that `raw_image` you inputted to display your image. It will then return the image displayed in the ndv viewer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c494d",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Use `ndv` to view the image `raw_image`\n",
    "Remember, we need to import ndv in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7447ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff935a",
   "metadata": {},
   "source": [
    "## 2. Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e517d3d",
   "metadata": {},
   "source": [
    "### Concept\n",
    "\n",
    "**Filters** change image pixel values using a **mathematical operation**. Here, we use them to smooth and reduce **noise** from images. Doing so can help improve thresholding results. \n",
    "\n",
    "### Applying a filter to an image\n",
    "Here's a summary of the filters we covered in lecture that are good at reducing noise from images: \n",
    "\n",
    "| Filter Name | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "| mean filter | For a given kernel size, sums values in a list and and then divides by the total number of values | `from skimage.filters.rank import mean` | [skimage.filters.rank.mean](https://scikit-image.org/docs/0.25.x/api/skimage.filters.rank.html#skimage.filters.rank.mean) |\n",
    "| Gaussian blur filter | For a given kernel size, multiply each value by a Gaussian profile weighting, then divide by the total number of values | `from skimage.filters import gaussian` | [skimage.filters.gaussian](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.gaussian) |\n",
    "| median filter | For a given kernel size, take the middle number in a sorted list of numbers | `from skimage.filters import median` | [skimage.filters.median](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.median) |\n",
    "\n",
    "Don't forget to review the documentation to see how to specify the kernel size for each filter!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to apply a Gaussian blur filter to `raw_image` and assign it to the variable `filtered_image`\n",
    "Remember - we need to import the `gaussian` function from `skimage.filters` in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "916684f9a58a4a2aa5f864670399430d",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: View `filtered_image` with `ndv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671c31a24314836a5b85d7ef7fbf015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40465674",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc95a1a",
   "metadata": {},
   "source": [
    "## 3. Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a24d030",
   "metadata": {},
   "source": [
    "### Concept\n",
    "\n",
    "**Thresholding** is when we select a range of digital values, or **intensity values**, in the image. These selected values are how we define regions of the image we are interested in. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8902ba",
   "metadata": {},
   "source": [
    "### Defining a threshold\n",
    "We need to define a minimum intensity cutoff which separates the **background** (what we don't care about) from the **foreground** (what we do care about). We can manually pick an intensity value as this cutoff value like below:\n",
    "```python\n",
    "threshold = 50\n",
    "```\n",
    "\n",
    "However, manually changing the value assigned to `threshold` until we find an optimal intensity cutoff value is tedious and may vary between images in a dataset. Therefore, it is best practice to instead use established **thresholding algorithms** to automatically define an intensity cutoff value. `skimage.filters` contains many different types of thresholding algorithms, but from that we will be using the Otsu thresholding algorithm `threshold_otsu`. \n",
    "\n",
    "| Thresholding Algorithm | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "| Otsu thresholding | Returns threshold using Otsu's method | `from skimage.filters import threshold_otsu` | [threshold_otsu](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.threshold_otsu) |\n",
    "\n",
    "<p class=\"alert alert-info\">\n",
    "    <strong>Note:</strong> <b>skimage.filters</b> also has a <b>try_all_threshold()</b> function that takes an inputted image and returns a figure comparing the outputs of different thresholding methods. It can be a helpful tool to pick a good thresholding algorithm!\n",
    "</p>\n",
    "\n",
    "We can use `threshold_otsu` from `skimage.filters` as follows: \n",
    "```python\n",
    "from skimage.filters import threshold_otsu # put in Setup\n",
    "threshold = threshold_otsu(filtered_image)\n",
    "```\n",
    "Here, `threshold_otsu()` will use that inputted `filtered_image` to calculate an intensity cutoff value. It will return the cutoff value assigned to the variable `threshold`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to calculate a threshold on `filtered_image` using Otsu's method\n",
    "Remember - we need to import the `threshold_otsu` function from `skimage.filters` in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b363d81ae4b689946ece5c682cd59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a65eabff63a45729fe45fb5ade58bdc",
   "metadata": {},
   "source": [
    "### Generating a binary mask\n",
    "We now want to use this cutoff value to generate a **binary mask**, which is an image that has only 2 pixel values: one corresponding to the background and one corresponding to the foreground. By generating the binary mask, we will be able to evaluate whether this `threshold` is a sufficient cutoff value. \n",
    "\n",
    "We can generate the binary mask by using *any* comparison operator. Since we want to accept values above a given threshold as foreground, let's use the comparison operator `>`:\n",
    "```python\n",
    "binary_mask = filtered_image > threshold\n",
    "```\n",
    "Python will interpret this line of code by going pixel by pixel through `filtered_image` and assigning `True` values where a pixel is greater than `threshold` and assigning `False` values where a pixel is equal or less than `threshold`. The output will be the binary mask image, filled with `True` and `False`. Since this binary mask is something we will be working with, we should assign it a variable, such as `binary_mask`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a79f80",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to threshold `filtered_image` and generate a binary image assigned to the variable `binary_mask`. Print this image's minimum and maximum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745cd7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "source": [
    "### Comparing the binary mask to the raw image\n",
    "We can use `matplotlib.pyplot` to view the `raw_image` and `binary_mask` side by side. We first need to import `matplotlib.pyplot` in Setup, which can be abbreviated as `plt` for simplicity. \n",
    "\n",
    "| Name | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "| `matplotlib.pyplot` | Creates interactive plots | `import matplotlib.pyplot as plt` | [matplotlib.pyplot](https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html) |\n",
    "\n",
    "Just as you learned in the last lesson, we can use `plt` to plot images. Plotting 2 images for side by side comparison is a very useful task, so let's package this code into a function. You can get started with the template below:\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt # put in Setup\n",
    "\n",
    "def double_image_plotter(img_1, img_2):\n",
    " \n",
    "    # Create a figure and axis\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 6))  # 1 row, 2 columns\n",
    "\n",
    "    # Plot images\n",
    "    # add code here!\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "We can then call this `double_image_plotter` function whenever we want to plot 2 images side by side! We can do that by writing:\n",
    "```python\n",
    "double_image_plotter(image_1, image_2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9082857fd66e4025bba99b1a80c5d976",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write a function named `double_image_plotter` that uses `plt` to plot two images side by side\n",
    "Remember to import `matplotlib.pyplot` as `plt` in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b4158a9f3d49279f06ec9197b84529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5a1fa73e5044315a093ec459c9be902",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: View `raw_image` and `binary_mask` side by side using the `double_image_plotter` function you just made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf66aed5cc84ca1b48e60bad68798a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce9951d2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71072aba",
   "metadata": {},
   "source": [
    "## 4. Mask Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4377aec2",
   "metadata": {},
   "source": [
    "### Concept\n",
    "\n",
    "Now that we have a binary mask that has white, or value `True`, pixels that match the image foreground and black, or value  `False`, pixels that match the image background, we can continue further to distinguish individual objects within this mask. **Labeling** a mask is when we identify individual objects within a binary mask and assign them a unique numerical identifier. \n",
    "\n",
    "### Labeling a binary mask\n",
    "From `skimage.measure` we can use `label()` to label a curated binary mask.\n",
    "\n",
    "| Function | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "| `label()` | Label connected regions of an image for Instance segmentation | `from skimage.measure import label` | [skimage.measure.label](https://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.label) |\n",
    "\n",
    "Here's how we use `label` from `skimage.measure` to label a binary mask: \n",
    "```python\n",
    "from skimage.measure import label # put in Setup\n",
    "labeled_image = label(binary_mask)\n",
    "```\n",
    "Here, `label()` will take the inputted `binary_mask` and count each connected object in the image. It will then assign each object a whole number starting from 1. It will then return an image where each object's pixels have the value of its object's assigned number, which we assign to the variable `labeled_image`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aed757",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to label `binary_mask` and assign it to the variable `labeled_image`\n",
    "Remember - we need to import the `label function` from `skimage.measure` in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced25859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "584c9a12",
   "metadata": {},
   "source": [
    "### Displaying a labeled mask on top of the image\n",
    "Let's now summarize our final segmentation result in 1 image by viewing the `labeled_image` overlaid onto the original `raw_image`. From `skimage.color`, we can use `label2rgb` to do this. \n",
    "\n",
    "| Function | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "| `label2rgb()` | Returns an RGB image where color-coded labels are painted over the image | `from skimage.color import label2rgb` | [label2rgb](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb) |\n",
    "\n",
    "Here's how we can use `label2rgb` from `skimage.color` to summarize our segmentation result: \n",
    "```python\n",
    "from skimage.color import label2rgb # put in Setup\n",
    "seg_summary = label2rgb(labeled_image, image = raw_image)\n",
    "```\n",
    "Here, `label2rgb()` is filled with 2 arguments: \n",
    "1. The labeled mask `labeled_image`\n",
    "2. The original image we want the `labeled_image` overlaid onto, specified as `image = raw_image`\n",
    "\n",
    "The output will be an rgb image of the labeled mask overlaid onto the raw image, which is assigned to the variable `seg_summary`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa0c30",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code that creates an image of `labeled_image` overlaid onto `raw_image` and assign it to the variable `seg_summary`\n",
    "Remember - we need to import the `label2rgb` function from `skimage.color` in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21627fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e382214b5f147d187d36a2058b9c724",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: View `seg_summary` with `plt.imshow()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b09d5ef5b5e4bb6ab9b829b10b6a29f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3933fab20d04ec698c2621248eb3be0",
   "metadata": {},
   "source": [
    "How does the segmentation result look? Are all labels corresponding to individual nuclei? If not, additional processing steps are needed to refine `binary_mask`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e582b",
   "metadata": {},
   "source": [
    "## 5. Mask Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e060920",
   "metadata": {},
   "source": [
    "### Concept\n",
    "\n",
    "**Mask refinement** is needed when a binary mask still does not accurately match the image foreground after filtering and thresholding. In the context of our nuclei example image, we need to apply additional processing steps to remove objects that are too small to be nuclei, fill any holes within nuclei, and separate touching nuclei.\n",
    "\n",
    "### Common mask refinement steps\n",
    "There are many different ways we can refine a binary mask. The table below summarizes the refinement steps we discussed in lecture:\n",
    "\n",
    "| Function Name | Description | How to import it | Documentation Link |\n",
    "|---------|---------|----------------|----------------|\n",
    "| `remove_small_objects()` | Removes objects smaller than the specified size from the foreground.  | `from skimage.morphology import remove_small_objects` | [skimage.morphology.remove_small_objects](https://scikit-image.org/docs/0.25.x/api/skimage.morphology.html#skimage.morphology.remove_small_objects) |\n",
    "| `binary_closing()` | Performs morphological closing, a mathematical operation that results in small hole removal | `from skimage.morphology import binary_closing` | [skimage.morphology.binary_closing](https://scikit-image.org/docs/stable/api/skimage.morphology.html#skimage.morphology.binary_closing) |\n",
    "| `watershed()` | Performs the Watershed transform, a useful algorithm for separating touching objects. The output is a labeled image. | `from skimage.segmentation import watershed` | [skimage.segmentation.watershed](https://scikit-image.org/docs/0.25.x/api/skimage.segmentation.html#skimage.segmentation.watershed) |\n",
    "\n",
    "Let's now walk through steps to remove objects smaller than nuclei with `remove_small_objects()`, fill in any holes within nuclei with `binary_closing()`, and then separate touching nuclei with `watershed()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4641cc4064e0191573fe9c69df29b",
   "metadata": {},
   "source": [
    "### Removing objects smaller than nuclei\n",
    "In many cases, thresholding will be unsuccessful at rejecting image objects that are debris, as these tend to have high intensity values. However, we can use differences in object size to reject anything that is too small to be a nucleus. \n",
    "\n",
    "From `skimage.morphology` we can use the `remove_small_objects` function to remove any connected objects of a specified `min_size`. Here is how we can do that:\n",
    "```python\n",
    "from skimage.morphology import remove_small_objects # put in Setup\n",
    "binary_mask_sized = remove_small_objects(binary_mask, min_size=10)\n",
    "```\n",
    "Here, `remove_small_objects()` will take the inputted `binary_mask` and set any connected object that is smaller than `min_size=10` to have `False` values (in other words, be rejected as foreground). It will then return the updated binary mask, which we assigned to the variable `binary_mask_sized`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8309879909854d7188b41380fd92a7c3",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to remove objects smaller than nuclei in `binary_mask` and assign it to the variable `binary_mask_sized`\n",
    "Remember, we need to import functions we want to use in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed186c9a28b402fb0bc4494df01f08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1944c39560714e6e80c856f20744a8e5",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Use our `double_image_plotter` function to display `binary_mask` and `binary_masked_sized` side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca27006b894b04b6fc8b79396e2797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb1e1581032b452c9409d6c6813c49d1",
   "metadata": {},
   "source": [
    "### Filling holes within nuclei\n",
    "While filtering helps reduce the effect of noise on thresholding, sometimes there will still be areas **within** an object that are below the minimum threshold value. These areas will show up as holes within a connected object. We can fill these holes by applying a morphological closing operation to the mask. \n",
    "\n",
    "From `skimage.morphology` we can use the `binary_closing` function to fill small holes within nuclei. Here is how we can do that:\n",
    "```python\n",
    "from skimage.morphology import binary_closing # put in Setup\n",
    "from skimage.morphology import disk # put in Setup\n",
    "binary_mask_filled = binary_closing(binary_mask_sized, disk(1))\n",
    "```\n",
    "Here, `binary_closing()` has two inputs: \n",
    "1. The binary mask `binary_mask_sized` \n",
    "2. A footprint `disk(1)`, which is a disk shaped kernel of size 1 \n",
    "\n",
    "It uses these inputs to perform a morphological closing operation optimized for binary images. It will then return the updated binary mask, which we assign to the variable `binary_mask_filled`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cbbc1e968416e875cc15c1202d7eb",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to fill holes within nuclei in `binary_mask_sized`, and assign the updated mask to the variable `binary_masked_filled`\n",
    "Remember, we need to import functions we want to use in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c27b1587741f2af2001be3712ef0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35ffc1ce1c7b4df9ace1bc936b8b1dc2",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Use our `double_image_plotter` function to display `binary_mask_sized` and `binary_mask_filled`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76127f4a2f6a44fba749ea7800e59d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db7b79bc585a40fcaf58bf750017e135",
   "metadata": {},
   "source": [
    "### Separating touching nuclei\n",
    "Let's now apply the Watershed transform to our `binary_mask` to separate any touching nuclei. From `skimage.segmentation`, we can use `watershed()` to do this. \n",
    "\n",
    "The `watershed()` function needs the following inputs:\n",
    "1. The inverse of the distance transform of the binary mask\n",
    "2. The seeds: labeled image of the peaks of the distance transform\n",
    "3. The binary mask\n",
    "\n",
    "We are going to need a few additional functions to provide the first two inputs to the `watershed()` function. \n",
    "\n",
    "| Function | Description | How to import it | Documentation Link |\n",
    "|---------|---------|----------------|----------------|\n",
    "| `distance_transform_edt()` | Calculates the distance transform of the input | `from scipy.ndimage import distance_transform_edt` | [scipy.ndimage.distance_transform_edt](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.distance_transform_edt.html) |\n",
    "| `peak_local_max` | Remove objects smaller than the specified size from the foreground.  | `from skimage.feature import peak_local_max` | [skimage.feature.peak_local_max](https://scikit-image.org/docs/0.25.x/api/skimage.feature.html#skimage.feature.peak_local_max) |\n",
    "\n",
    "#### Computing the distance transform\n",
    "We can use the `distance_transform_edt()` function from `scipy.ndimage` to get the distance transform of our refined binary_mask `binary_mask_filled`:\n",
    "```python\n",
    "from scipy.ndimage import distance_transform_edt # put in Setup\n",
    "# compute the distance transform\n",
    "distance_transform = distance_transform_edt(binary_mask_filled)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to calculate the distance transform of `binary_mask_filled` and assign it to the variable `distance_transform`\n",
    "Remember to import what you need in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3efd5258a48a79c179ea5c6759f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f9bc0b9dd2c44919cc8dcca39b469f8",
   "metadata": {},
   "source": [
    "#### Creating seeds for Watershed\n",
    "Once we have the distance transform of `binary_mask_filled`, we can use the `peak_local_max()` function from `skimage.feature` to get its local maxima. However, we want to make sure that we get only 1 local maximum per object. We therefore can apply a `footprint` input confine a region the `peak_local_max` function will look for local maxima. Doing so will constrain how many maxima the function returns. We can also specify a `min_distance` separating peaks, which will also help constrain the number of maxima to be 1 per nucleus. \n",
    "\n",
    "Here's how we would write the code:\n",
    "``` python\n",
    "from skimage.feature import peak_local_max # put in Setup\n",
    "# find local maxima coordinates in the distance transform\n",
    "local_maxima_coords = peak_local_max(distance_transform, footprint=np.ones((25, 25)), min_distance=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebfc27",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code that finds the local maxima coordinates of `distance_transform`. Print the coordinates to see how they are organized.\n",
    "Remember to import what you need in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31967ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5db69742",
   "metadata": {},
   "source": [
    "Now that we have the local maxima, we need to organize them for the `watershed()` function as a labeled image. We can do that by creating a binary image that's the same size as our binary mask. We will want all values in this new image to be `False` except where the local maxima are. Therefore, let's use `np.zeros_like()` to create a binary image filled with `False` values that's the same size as `binary_mask`:\n",
    "```python\n",
    "#create image that's the same size and dtype as binary_mask_filled\n",
    "local_maxima_image = np.zeros_like(binary_mask_filled, dtype=bool) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4e7bcd",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code that creates an image of `dtype=bool` that is the same size as `binary_mask`. Assign it to the variable `local_maxima_image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fb4eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7307caf",
   "metadata": {},
   "source": [
    "Now we need to add the `local_maxima_coords` to this new `local_maxima_image`. This is a tricky task, because `local_maxima_coords` organizes each (x,y) coordinate of where a local maximum is like this: \n",
    "```python\n",
    "[[10, 20], # first peak at (row=10, col=20)\n",
    "[30, 40], # second peak at (row=30, col=40)\n",
    "[50, 60]] # third peak at (row=50, col=60)\n",
    "```\n",
    "\n",
    "We need a way to organize these coordinates so that we can insert all of the row and columns as separate arrays into `local_maxima_coords`. In other words, we need to organize the coordinates so they look like this: \n",
    "```python \n",
    "[[10, 30, 50],  # all row indices\n",
    "[20, 40, 60]]   # all column indices\n",
    "```\n",
    "We can do that by taking the **transpose** of `local_maxima_coords`. A transpose flips a matrix over its diagonal axis, effectively swapping rows and columns. In Python, we take the transpose of an np.array by writing:\n",
    "```python\n",
    "local_maxima_coords.T\n",
    "```\n",
    "Here, the \".T\" indicates that we want the transpose of `local_maxima_coords`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3c6054",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code that takes the transpose of `local_maxima_coords`, then print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03705a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63ad0c95",
   "metadata": {},
   "source": [
    "We still have some work to do to get these coordinates into `local_maxima_image`. To pass the coordinates into `local_maxima_image`, we need to organize them as a tuple. We can do that with the `tuple()` function: \n",
    "```python\n",
    "tuple(local_maxima_coords.T)\n",
    "```\n",
    "Now, the coordinates will be arranged as so: \n",
    "```python\n",
    "array([10, 30, 50]),  # all row indices\n",
    "array([20, 40, 60])   # all column indices\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe7fff",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code that converts the transpose of `local_maxima_coords` to a tuple. Print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bedb53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e531abe",
   "metadata": {},
   "source": [
    "This is exactly what we want them to look like to insert into `local_maxima_image`! Here's how we can insert them:\n",
    "```python\n",
    "local_maxima_image[tuple(local_maxima_coords.T)]\n",
    "```\n",
    "\n",
    "The last thing we need to do is make them all have value `True`, since `local_maxima_image` is a binary image. We can do that by writing:\n",
    "```python\n",
    "# add the local_maxima_coords to the created local_maxima_image, after doing some work to organize them\n",
    "local_maxima_image[tuple(local_maxima_coords.T)] = True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b530ee8",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code that adds the `local_maxima_coords` to `local_maxima_image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the local_maxima_coords to the created local_maxima image\n",
    "local_maxima_image[tuple(local_maxima_coords.T)] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc5981",
   "metadata": {},
   "source": [
    "Finally, we can label `local_maxima_image` to create seeds for the Watershed function.\n",
    "```python\n",
    "# label the local_maxima_image to create seeds for the watershed function\n",
    "seeds = label(local_maxima_image)\n",
    "```\n",
    "\n",
    "Hooray! We have our seeds! Let's now put all of what we just learned together about how we used `distance_transform` to create `seeds`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50416e276a0479cbe66534ed1713a40",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code that uses `distance_transform` to create seeds for the Watershed algorithm. Assign the seeds to the variable `seeds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a27a456b804aa2a380d5edf15a5daf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f61877af4e7f4313ad8234302950b331",
   "metadata": {},
   "source": [
    "#### Applying the Watershed Transform\n",
    "Now we have everything we need to input into the `watershed()` function:\n",
    "1. The inverse of the distance transform of the binary mask: `-distance_transform`\n",
    "2. The seeds: `seeds`\n",
    "3. The binary mask: `binary_mask_filled`\n",
    "\n",
    "We can now call the Watershed function as follows:\n",
    "``` python\n",
    "# apply the watershed algorithm to segment the image and get labels\n",
    "from skimage.segmentation import watershed # put in Setup\n",
    "labeled_ws_image = watershed(-distance_transform, seeds, mask=binary_mask_filled)\n",
    "```\n",
    "\n",
    "Here, `watershed()` will apply the Watershed Transform to the inputted `binary_image_filled`. It will return the transformed, **labeled** image. We assign it to the variable `labeled_ws_image`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd599b",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to apply a watershed transform to `binary_mask_filled` and assign it to the variable `labeled_ws_image`\n",
    "Remember to import what you need in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e822bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81ff116bae5b45f6b6dae177083008cf",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Use `label2rgb()` to create an image of `labeled_ws_image` overlaid onto `raw_image` and assign it to the variable `seg_summary_refined`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075f00cfa8d463f84130041b1e44ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15abde8c5d2e435093904b13db685a53",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Use `plt` to display `seg_summary_refined`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e20a2a0e21149b5b06860e930401eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "source": [
    "## END OF FIRST LAB SECTION - STOP HERE FOR LAST LECTURE COMPONENT!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bcb4dd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "source": [
    "## 6. Processing Many Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": [
    "### Concept\n",
    "\n",
    "Statistically relevant & reproducible measurements come from analyzing many fluorescence images. Therefore, we need to adapt our code to efficiently run on many images, not just 1 at a time! We can do so by implementing a `for` loop to our image path handling. We can also add the ability to save output files using `tifffile.imwrite()`.\n",
    "\n",
    "### Consolidate code for image processing steps\n",
    "The first step to processing many images is to write code to process a single image, just as we have done above in the previous sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d5ab97d17b4c38ab41a2b065bbd0c0",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Copy and paste all of the code we wrote in the above sections to load and segment our single nucleus image\n",
    "\n",
    "Remember, we want code that does the following steps: \n",
    "* Specify dependencies\n",
    "* Load the image\n",
    "* Filter the image with a Gaussian filter\n",
    "* Threshold to generate a binary mask\n",
    "* Refine the mask: Remove small objects\n",
    "* Refine the mask: Fill small  holes\n",
    "* Refine the mask: Watershed\n",
    "* Review our final segmentation summary with label2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903197826d2e44dfa0208e8f97c69327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "015066fb96f841e5be1e03a9eaadc3b6",
   "metadata": {},
   "source": [
    "### Using a `for` loop to loop through image paths\n",
    "Now that we have the code in one place, we need to adapt it to be able to process more than one image. We can do that by looping through image file paths. From `pathlib`, we can use `Path` in conjunction with a `for` loop to iterate through many image file paths in a specified folder directory. Here's how we would write the code to do that:\n",
    "```python\n",
    "from pathlib import Path\n",
    "folder_dir = Path(\"/Users/edelase/bobiac/\") # update with your folder directory\n",
    "for image_path in folder_dir.iterdir():\n",
    "    # do things\n",
    "```\n",
    "\n",
    "Providing the function `Path` with a folder directory points Python to the folder we want to access files from. We assign it to the variable `folder_dir` to make it easy to work with. Writing `folder_dir.iterdir()` points to this folder we want to work in, and hands us all file paths within the folder. Since we want to loop through each file path in the folder, we set up our `for` loop to take each `image_path` within what `folder_dir.iterdir()` provides from the folder. We can then do whatever tasks we would like for each `image_path`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c31777baf4441b988909d29205560c",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write a for loop that prints all image file paths in a folder using `Path` and `iterdir()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734001bcbac423990a4356310d8df13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27531e93873647d9a5bf1112f2051a59",
   "metadata": {},
   "source": [
    "### Using `glob` to loop through *only* tif image paths\n",
    "What if we have more than just tif images in our folder? Instead of using `iterdir()`, we can selectively loop through files ending with \".tif\" using `glob`. Here's how we would write the code to do that:\n",
    "```python\n",
    "from pathlib import Path\n",
    "import glob\n",
    "folder_dir = Path(\"/Users/edelase/bobiac/\")\n",
    "for image_path in folder_dir.glob(\"*.tif\"): # only loop through files ending in .tif\n",
    "    # do things\n",
    "```\n",
    "\n",
    "Here, we are still using `Path` to point Python to the folder we want to access files from. However, instead of using `iterdir()` to hand us all file paths within the folder, we are using `glob` to only hand us file paths in the folder ending with \".tif\". We are then looking through each of these file paths. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3041e9ffdb2416ea2009d3a6a4c5716",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write a for loop that prints all tif image file paths in a folder using `Path` and `glob`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae71b6e24e4355a139fb9fe2e09b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9141936c6c8a4c478a75aea4ff665469",
   "metadata": {},
   "source": [
    "### Using a `for` loop to process many images\n",
    "Now that we have learned how to loop through image paths efficiently, we can now apply this concept to increase the throughput of our classic segmentation processing code. We can do that by putting each processing step, starting with reading the image, within the for loop. \n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "import glob\n",
    "folder_dir = Path(\"/Users/edelase/bobiac/\")\n",
    "for image_path in folder_dir.glob(\"*.tif\"): # only loop through files ending in .tif\n",
    "    # load the image\n",
    "    raw_image = tifffile.imread(image_path)\n",
    "    ...\n",
    "    break # Use for troubleshooting! Only do first loop until confident you're ready to loop through all files\n",
    "```\n",
    "\n",
    "Here, Python will loop through each `image_path` ending with \".tif\" in `folder_dir` and conduct the indented lines of code. Until we're ready to loop through all images and complete processing steps, we can use `break` as a last indented step in our `for` loop to only complete 1 loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c096f4dcf400fbdceb075ef31fca3",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Improve your classic segmentation code above by adding a for loop to process many images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427a666a1b549ef9b573d6f946bfc3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0310869696a145bf841235dd6c036af8",
   "metadata": {},
   "source": [
    "### Saving Output Files\n",
    "Now that we have our for loop set up, we can modify our code to save the `labeled_ws_image` as an outputted tif file. We can do this using `tifffile.imwrite()`. Here's how we can write the code:\n",
    "\n",
    "```python\n",
    "output_dir = Path(\"/Users/edelase/bobiac/results\")\n",
    "tifffile.imwrite(output_dir/\"output_image.tif\", labeled_ws_image.astype(\"uint32\"))\n",
    "```\n",
    "\n",
    "Here, `tifffile.imwrite` is provided with 2 inputs: \n",
    "1. `output_dir/\"output_image.tif\"` is the **file path** the image will be saved to, which ends with a specified **file name**\n",
    "2.  `labeled_ws_image.astype(\"uint32\")` is a specification for the data being saved as \"uint32\", or 32 bit\n",
    "\n",
    "`tifffile.imread()` will use these two inputs to output a file saved to the `output_dir` folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f166d9f0ce4939b04b8e9245f75c27",
   "metadata": {},
   "source": [
    "<p class=\"alert alert-info\">\n",
    "    <strong>NOTE:</strong> The <b>dtype</b> of a labeled image is important because it determines the maximum number of labels stored in the image. Since each object in a labeled image is assigned a unique integer label, the dtype determines the range of integers that can be used for this labeling (e.g. uint8 -> max 255 objects). By default, labels generated by the <b>skimage.measure.label()</b> function are of type <b>uint32</b>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10029e1707434ab3fe295caea7d13f",
   "metadata": {},
   "source": [
    "When we provide `tifffile.imwrite()` with an output file path, we run into a problem. We can't just directly write, or **hard code**, a file name for the image we are trying to save because it will be different for each iteration of our `for` loop. Therefore, we need a way to automatically generate a file name for each loop. We can do this by accessing the `stem` of a given `image_path`, which would give us the starting file name without the .tif at the end:\n",
    "\n",
    "```python\n",
    "image_path.stem # returns file name, without .tif at the end, from image_path\n",
    "```\n",
    "\n",
    "Let's see this in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f0888c55a4478ace3eac39384dff4",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Print the file name of each tif image in your folder using `stem`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94f5a17fa734d288763e7d9a3758173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6038e703eb6b4df2ba5a71336b77ea4e",
   "metadata": {},
   "source": [
    "However, we want to add a \".tif\" at the end, as well as an additional label to the file name to distinguish it from the original `raw_image`. We can do the following to add a \"_labeled.tif\" at the end of the file name:\n",
    "\n",
    "```python\n",
    "f\"{image_path.stem}_labeled.tif\"\n",
    "```\n",
    "Here, the `f` before the double quotes to start a `str` cues Python to know that this is a **formatted string**. Formatted strings are a way to insert variables into strings. In this case, we are inserting the file name that `image_path.stem` returns into the beginning of a string that ends with `\"_labeled.tif\"`. Together, this will give us the full file name to save the image. \n",
    "\n",
    "To make it a full file path, we can combine it with our `output_dir`:\n",
    "```python\n",
    "output_filepath = output_dir/f\"{image_path.stem}_labeled.tif\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca0f16c5be4617b5535c40faa36c79",
   "metadata": {},
   "source": [
    "Now, let's apply these modifications to our image processing code: \n",
    "\n",
    "```python\n",
    "input_dir = Path(\"/Users/edelase/bobiac/\")\n",
    "output_dir = Path(\"/Users/edelase/bobiac/results\")\n",
    "for image_path in input_dir.glob(\"*.tif\"): # only loop through files ending in .tif\n",
    "    # do processing steps\n",
    "\n",
    "    # save file\n",
    "    output_filepath = output_dir/f\"{image_path.stem}_labeled.tif\"\n",
    "    tifffile.imwrite(output_filepath, labeled_ws_image.astype(\"uint32\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b839107204e409e0496d3d944026c",
   "metadata": {},
   "source": [
    "Now, let's apply these concepts to our segmentation code so that we can save each final labeled image as an outputted tif file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981b37c798e44f684168605b9db02c6",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Modify your classic segmentation code that processes many images to save each `labeled_ws_image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1800d1c114147a536b8aa907907c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46cf9ddf",
   "metadata": {},
   "source": [
    "When you are happy with the code, simply remove the `break` statement to run the code on all images in the folder (maybe also remove the visualization step)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
