{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899601d4",
   "metadata": {},
   "source": [
    "# Retraining Cellpose on Custom Data\n",
    "\n",
    "<div class=\"custom-button-row\">\n",
    "    <a \n",
    "        class=\"custom-button custom-download-button\" href=\"../../../notebooks/05_segmentation/deep_learning/cellpose_retraining_notebook.ipynb\" download>\n",
    "        <i class=\"fas fa-download\"></i> Download this Notebook\n",
    "    </a>\n",
    "    <a\n",
    "    class=\"custom-button custom-download-button\" href=\"https://colab.research.google.com/github/HMS-IAC/bobiac/blob/gh-pages/colab_notebooks/05_segmentation/deep_learning/cellpose_retraining_notebook.ipynb\" target=\"_blank\">\n",
    "        <img class=\"button-icon\" src=\"../../../_static/logo/icon-google-colab.svg\" alt=\"Open in Colab\">\n",
    "        Open in Colab\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbca03c3",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this section, weâ€™ll walk through how to **retrain Cellpose on your own data**. This is useful when the default models donâ€™t perform well on your specific cell type, staining method, or imaging modality.\n",
    "\n",
    "Retraining allows Cellpose to learn directly from your examplesâ€”leading to better segmentation accuracy and more relevant masks for your experiments.\n",
    "\n",
    "Weâ€™ll cover:\n",
    "- Preparing your training data (images + label masks)\n",
    "- Mounting your Google Drive to access files\n",
    "- Setting training parameters\n",
    "- Running the training process\n",
    "- Evaluating the new model on test images\n",
    "\n",
    "> ðŸ’¡ Youâ€™ll need pairs of raw microscopy images and their corresponding label masks. If you havenâ€™t labeled your images yet, we recommend using the [Cellpose GUI](https://cellpose.readthedocs.io/en/latest/gui.html#training-your-own-cellpose-model) to draw or edit masks manually before starting.\n",
    "\n",
    "The dataset weâ€™ll use here can be downloaded below. It includes both training and test images:\n",
    "<a href=\"../../../_static/data/05_segmentation_cellpose_training.zip\" download>\n",
    "<i class=\"fas fa-download\"></i> Cellpose Training Dataset</a>\n",
    "\n",
    "> âš ï¸ Note: If you're using an Apple Silicon Mac or don't have GPU support locally, please run this notebook on **Google Colab** to speed up training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3324fa",
   "metadata": {},
   "source": [
    "## Make sure you have GPU access\n",
    "\n",
    "To Enable GPU:\n",
    "\n",
    "1. navigate to `Runtime -> Change Runtime Type`\n",
    "2. select `Python 3` as `Runtime Type`\n",
    "3. select one available GPU (e.g. `T4 GPU`) as `Hardware accelerator`.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"left\"> <img src=\"https://raw.githubusercontent.com/HMS-IAC/bobiac/main/_static/images/cellpose/colab_runtime.png\" alt=\"Ilastik Logo\" width=\"400\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a179c14a",
   "metadata": {},
   "source": [
    "## Mount your google drive\n",
    "\n",
    "To access the data for the course you first need to mount your Google Drive.\n",
    "\n",
    "Run the cell below to connect your Google Drive to colab and follow the instructions to authenticate your Google account.\n",
    "\n",
    "You will need to allow access to your Google Drive so that the notebook can read and write files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15b00ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b4150",
   "metadata": {},
   "source": [
    "\n",
    "Then click on `folder icon` on the left bar, press the `refresh button`. Your Google Drive folder should now be available here (e.g. MyDrive).\n",
    "\n",
    "<div align=\"left\"> <img src=\"https://raw.githubusercontent.com/HMS-IAC/bobiac/main/_static/images/cellpose/colab_folder.png\" alt=\"Ilastik Logo\" width=\"300\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada69390",
   "metadata": {},
   "source": [
    "## Download the Data\n",
    "\n",
    "Run the cell below to download the data for this exercise and save it in you Google Drive. A new folder called `bobiac_data_cellpose` will be created in your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf5a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory\n",
    "!mkdir -p /content/bobiac_data_cellpose\n",
    "# Download the data\n",
    "!wget https://raw.githubusercontent.com/HMS-IAC/bobiac/main/_static/data/05_segmentation_cellpose_training.zip -O /content/bobiac_data_cellpose/05_segmentation_cellpose_training.zip\n",
    "# Unzip the data, remove zip file and macOS metadata files (if any)\n",
    "!cd /content/bobiac_data_cellpose && unzip 05_segmentation_cellpose_training.zip && rm -f 05_segmentation_cellpose_training.zip && rm -rf __MACOSX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2917b1b",
   "metadata": {},
   "source": [
    "## Install Cellpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f45e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cellpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f8a21f",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0b76f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v\n",
      "cellpose version: \t4.0.6 \n",
      "platform:       \tdarwin \n",
      "python version: \t3.13.0 \n",
      "torch version:  \t2.7.1! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU excution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tifffile\n",
    "from cellpose import core, io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5430eaff",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b8b8128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 19:55:40,389 [INFO] WRITING LOG OUTPUT TO /Users/ranit/.cellpose/run.log\n",
      "2025-07-11 19:55:40,390 [INFO] \n",
      "cellpose version: \t4.0.6 \n",
      "platform:       \tdarwin \n",
      "python version: \t3.13.0 \n",
      "torch version:  \t2.7.1\n",
      "2025-07-11 19:55:40,435 [INFO] ** TORCH MPS version installed and working. **\n",
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "io.logger_setup()  # run this to get printing of progress\n",
    "\n",
    "print(\"GPU available:\", core.use_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0dc776",
   "metadata": {},
   "source": [
    "### Init the Model\n",
    "\n",
    "Before we can train a new model, we need to initialize Cellpose with the correct settings.\n",
    "\n",
    "Here, weâ€™ll:\n",
    "- Specify the **model type** (e.g., \"cyto\" or \"nuclei\") to use as a base model\n",
    "- Set the **channels** depending on how your images are structured (e.g., single-channel grayscale, or dual-channel with nuclei and cytoplasm)\n",
    "- Choose where to **save the model weights** during training\n",
    "\n",
    "> ðŸ’¡ Even when training a new model, Cellpose builds on a pre-trained backbone (unless you explicitly start from scratch). This helps it learn faster and perform betterâ€”especially on small datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd65e527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 09:27:02,987 [INFO] ** TORCH MPS version installed and working. **\n",
      "2025-07-11 09:27:02,987 [INFO] >>>> using CPU\n",
      "2025-07-11 09:27:02,987 [INFO] >>>> using CPU\n",
      "2025-07-11 09:27:03,811 [INFO] >>>> loading model /Users/ranit/.cellpose/models/cpsam\n"
     ]
    }
   ],
   "source": [
    "from cellpose import core, io, models, plot\n",
    "from natsort import natsorted\n",
    "\n",
    "# Check if colab notebook instance has GPU access\n",
    "if core.use_gpu():\n",
    "    gpu = True\n",
    "else:\n",
    "    gpu = False\n",
    "    raise ImportError(\"No GPU access, change your runtime\")\n",
    "\n",
    "\n",
    "# Initialize the Cellpose model\n",
    "model = models.CellposeModel(gpu=gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c9514",
   "metadata": {},
   "source": [
    "## Data Handling\n",
    "\n",
    "For training, Cellpose expects:\n",
    "- A folder of raw images (e.g., TIFF or PNG)\n",
    "- A matching folder of masks, where each mask corresponds to an image and contains labeled regions\n",
    "\n",
    "Youâ€™ll also need to **split your data** into a training set and a test set. This allows the model to learn from one portion of the data, and then be evaluated on a separate portion it hasn't seen before.\n",
    "\n",
    "> âœ… The images and masks must have the **same filenames** (e.g., `img001.png` and `img001_masks.png`) so Cellpose can pair them correctly.\n",
    "\n",
    "During training, Cellpose will:\n",
    "- Load batches of training images\n",
    "- Compare its predictions to the ground-truth masks\n",
    "- Adjust itself (via backpropagation) to reduce errors over time\n",
    "\n",
    "Keep your training and test folders organized and double-check for any mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5268c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 09:27:06,787 [INFO] not all flows are present, running flow generation for all images\n",
      "2025-07-11 09:27:06,810 [INFO] 5 / 5 images in ../../../_static/data/05_segmentation_cellpose_training/train/ folder have labels\n",
      "2025-07-11 09:27:06,812 [INFO] not all flows are present, running flow generation for all images\n",
      "2025-07-11 09:27:06,829 [INFO] 3 / 3 images in ../../../_static/data/05_segmentation_cellpose_training/test/ folder have labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "ROOT_FOLDER_PATH = \"../../../_static/data/05_segmentation_cellpose_training/\"\n",
    "\n",
    "train_dir = os.path.join(ROOT_FOLDER_PATH, \"train/\")\n",
    "test_dir = os.path.join(ROOT_FOLDER_PATH, \"test/\")\n",
    "\n",
    "masks_ext = \"_seg.npy\"\n",
    "\n",
    "# get files\n",
    "train_data, train_labels, _, test_data, test_labels, _ = io.load_train_test_data(train_dir, test_dir, mask_filter=masks_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f87b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert images to float32\n",
    "train_data = [img.astype(np.float32) for img in train_data]\n",
    "# Convert labels (masks) to int32\n",
    "train_labels = [lbl.astype(np.int32) for lbl in train_labels]\n",
    "\n",
    "# Convert test images to float32 and labels to int32\n",
    "test_data = [img.astype(np.float32) for img in test_data]\n",
    "test_labels = [lbl.astype(np.int32) for lbl in test_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7c583a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 09:27:09,482 [INFO] 0%|          | 0/3 [00:00<?, ?it/s]\n",
      "2025-07-11 09:27:49,597 [INFO] 33%|###3      | 1/3 [00:40<01:20, 40.11s/it]\n",
      "2025-07-11 09:28:30,621 [INFO] 67%|######6   | 2/3 [01:21<00:40, 40.65s/it]\n",
      "2025-07-11 09:29:13,093 [INFO] 100%|##########| 3/3 [02:03<00:00, 41.48s/it]\n",
      "2025-07-11 09:29:13,095 [INFO] 100%|##########| 3/3 [02:03<00:00, 41.20s/it]\n",
      "\n",
      ">>> average precision at iou threshold 0.5 = 0.731\n"
     ]
    }
   ],
   "source": [
    "from cellpose import metrics\n",
    "\n",
    "# run model on test images\n",
    "masks = model.eval(test_data, batch_size=32)[0]\n",
    "\n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print(\"\")\n",
    "print(f\">>> average precision at iou threshold 0.5 = {ap[:, 0].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5400c63d",
   "metadata": {},
   "source": [
    "## Train New Model\n",
    "\n",
    "Now weâ€™re ready to train! In this step, weâ€™ll tell Cellpose to:\n",
    "- Use the training images and masks\n",
    "- Save the trained model to your specified directory\n",
    "- Run for a defined number of **epochs** (iterations over the full dataset)\n",
    "\n",
    "You can also set other options like:\n",
    "- Learning rate\n",
    "- Batch size\n",
    "- Whether to use GPU\n",
    "\n",
    "> ðŸ’¡ Training time will vary depending on your dataset size and hardware. On Google Colab with a GPU, small datasets may train in just a few minutes.\n",
    "\n",
    "After training, the model weights will be saved and ready to use for predictions. Weâ€™ll evaluate performance on the test data in the next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cae3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 09:29:16,536 [INFO] computing flows for labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 09:29:17,499 [INFO] >>> computing diameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 1860.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 09:29:17,503 [INFO] >>> normalizing {'lowhigh': None, 'percentile': None, 'normalize': True, 'norm3D': True, 'sharpen_radius': 0, 'smooth_radius': 0, 'tile_norm_blocksize': 0, 'tile_norm_smooth3D': 1, 'invert': False}\n",
      "2025-07-11 09:29:17,511 [INFO] >>> n_epochs=10, n_train=5, n_test=None\n",
      "2025-07-11 09:29:17,511 [INFO] >>> AdamW, learning_rate=0.00001, weight_decay=0.10000\n",
      "2025-07-11 09:29:17,513 [INFO] >>> saving model to /Users/ranit/Research/github/bobiac/content/05_segmentation/deep_learning/models/new_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 09:56:13,685 [INFO] 0, train_loss=1.1414, test_loss=0.0000, LR=0.000000, time 1616.17s\n"
     ]
    }
   ],
   "source": [
    "from cellpose import train\n",
    "\n",
    "model_name = \"new_model\"\n",
    "\n",
    "# Training params\n",
    "n_epochs = 10\n",
    "learning_rate = 1e-5\n",
    "weight_decay = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# (not passing test data into function to speed up training)\n",
    "\n",
    "new_model_path, train_losses, test_losses = train.train_seg(\n",
    "    model.net,\n",
    "    train_data=train_data,\n",
    "    train_labels=train_labels,\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=n_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    nimg_per_epoch=max(2, len(train_data)),  # can change this\n",
    "    model_name=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fcc0a6",
   "metadata": {},
   "source": [
    "## Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import metrics\n",
    "\n",
    "model = models.CellposeModel(gpu=True, pretrained_model=new_model_path)\n",
    "\n",
    "# run model on test images\n",
    "masks = model.eval(test_data, batch_size=32)[0]\n",
    "\n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print(\"\")\n",
    "print(f\">>> average precision at iou threshold 0.5 = {ap[:, 0].mean():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bobiac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
