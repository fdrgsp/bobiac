{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899601d4",
   "metadata": {},
   "source": [
    "# Retraining Cellpose on Custom Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbca03c3",
   "metadata": {},
   "source": [
    "## <mark style=\"color: black; background-color: rgb(127,196,125); padding: 3px; border-radius: 5px;\">Overview</mark>\n",
    "\n",
    "In this section, we‚Äôll walk through how to **retrain Cellpose on your own data**. This is useful when the default models don‚Äôt perform well on your specific cell type, staining method, or imaging modality.\n",
    "\n",
    "Retraining allows Cellpose to learn directly from your examples‚Äîleading to better segmentation accuracy and more relevant masks for your experiments.\n",
    "\n",
    "We‚Äôll cover:\n",
    "- Preparing your training data (images + label masks)\n",
    "- Mounting your Google Drive to access files\n",
    "- Setting training parameters\n",
    "- Running the training process\n",
    "- Evaluating the new model on test images\n",
    "\n",
    "> üí° You‚Äôll need pairs of raw microscopy images and their corresponding label masks. If you haven‚Äôt labeled your images yet, we recommend using the [Cellpose GUI](https://cellpose.readthedocs.io/en/latest/gui.html#training-your-own-cellpose-model) to draw or edit masks manually before starting.\n",
    "\n",
    "The dataset we‚Äôll use here can be downloaded below. It includes both training and test images:\n",
    "<a href=\"../../../_static/data/05_segmentation_cellpose_training.zip\" download>\n",
    "<i class=\"fas fa-download\"></i> Cellpose Training Dataset</a>\n",
    "\n",
    "<p class=\"alert alert-warning\">\n",
    "    <strong>‚ö†Ô∏è Note:</strong> This notebook is designed to run in <a href=\"https://colab.research.google.com/github/HMS-IAC/bobiac/blob/gh-pages/colab_notebooks/05_segmentation/deep_learning/cellpose_retraining_notebook.ipynb\" target=\"_blank\"> Google Colab</a>. If you want to run it locally, you may need to adjust some paths and install the required packages.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3324fa",
   "metadata": {},
   "source": [
    "## <mark style=\"color: black; background-color: rgb(127,196,125); padding: 3px; border-radius: 5px;\">Make sure you have GPU access</mark>\n",
    "\n",
    "To Enable GPU:\n",
    "\n",
    "1. navigate to `Runtime -> Change Runtime Type`\n",
    "2. select `Python 3` as `Runtime Type`\n",
    "3. select one available GPU (e.g. `T4 GPU`) as `Hardware accelerator`.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"left\"> <img src=\"https://raw.githubusercontent.com/HMS-IAC/bobiac/main/_static/images/cellpose/colab_runtime.png\" alt=\"Ilastik Logo\" width=\"400\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a179c14a",
   "metadata": {},
   "source": [
    "## <mark style=\"color: black; background-color: rgb(127,196,125); padding: 3px; border-radius: 5px;\">Mount your google drive</mark>\n",
    "\n",
    "To access the data for the course you first need to mount your Google Drive.\n",
    "\n",
    "Run the cell below to connect your Google Drive to colab and follow the instructions to authenticate your Google account.\n",
    "\n",
    "You will need to allow access to your Google Drive so that the notebook can read and write files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15b00ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b4150",
   "metadata": {},
   "source": [
    "\n",
    "Then click on `folder icon` on the left bar, press the `refresh button`. Your Google Drive folder should now be available here (e.g. MyDrive).\n",
    "\n",
    "<div align=\"left\"> <img src=\"https://raw.githubusercontent.com/HMS-IAC/bobiac/main/_static/images/cellpose/colab_folder.png\" alt=\"Ilastik Logo\" width=\"300\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada69390",
   "metadata": {},
   "source": [
    "## <mark style=\"color: black; background-color: rgb(127,196,125); padding: 3px; border-radius: 5px;\">Download the Data</mark>\n",
    "\n",
    "Run the cell below to download the data for this exercise and save it in you Google Drive. A new folder called `bobiac_data_cellpose` will be created in your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf5a25b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create directory\n",
    "!mkdir -p /content/bobiac_data_cellpose\n",
    "# Download the data\n",
    "!wget https://raw.githubusercontent.com/HMS-IAC/bobiac/main/_static/data/05_segmentation_cellpose_training.zip -O /content/bobiac_data_cellpose/05_segmentation_cellpose_training.zip\n",
    "# Unzip the data, remove zip file and macOS metadata files (if any)\n",
    "!cd /content/bobiac_data_cellpose && unzip 05_segmentation_cellpose_training.zip && rm -f 05_segmentation_cellpose_training.zip && rm -rf __MACOSX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2917b1b",
   "metadata": {},
   "source": [
    "## <mark style=\"color: black; background-color: rgb(127,196,125); padding: 3px; border-radius: 5px;\">Install Cellpose</mark>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f45e77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install cellpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f8a21f",
   "metadata": {},
   "source": [
    "## <mark style=\"color: black; background-color: rgb(127,196,125); padding: 3px; border-radius: 5px;\">Import Libraries</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0b76f9",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from cellpose import core, io, metrics, models, train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5430eaff",
   "metadata": {},
   "source": [
    "## <mark style=\"color: black; background-color: rgb(127,196,125); padding: 3px; border-radius: 5px;\">Setup</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b8128",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "io.logger_setup()  # to get printing of progress\n",
    "\n",
    "use_gpu = core.use_gpu()\n",
    "print(\"GPU available:\", use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c9514",
   "metadata": {},
   "source": [
    "## <mark style=\"color: black; background-color: rgb(127,196,125); padding: 3px; border-radius: 5px;\">Data Handling</mark>\n",
    "\n",
    "For training, Cellpose expects:\n",
    "- A folder of raw images (e.g., TIFF or PNG)\n",
    "- A matching folder of masks, where each mask corresponds to an image and contains labeled regions\n",
    "\n",
    "You‚Äôll also need to **split your data** into a training set and a test set. This allows the model to learn from one portion of the data, and then be evaluated on a separate portion it hasn't seen before.\n",
    "\n",
    "> ‚úÖ The images and masks must have the **same filenames** (e.g., `img001.png` and `img001_masks.png`) so Cellpose can pair them correctly.\n",
    "\n",
    "During training, Cellpose will:\n",
    "- Load batches of training images\n",
    "- Compare its predictions to the ground-truth masks\n",
    "- Adjust itself (via backpropagation) to reduce errors over time\n",
    "\n",
    "Keep your training and test folders organized and double-check for any mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5268c54",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "ROOT_FOLDER_PATH = Path(\"data/05_segmentation_cellpose/retraining\")\n",
    "\n",
    "train_dir = ROOT_FOLDER_PATH / \"train\"\n",
    "test_dir = ROOT_FOLDER_PATH / \"test\"\n",
    "\n",
    "masks_ext = \"_seg.npy\"\n",
    "\n",
    "# get files\n",
    "train_data, train_labels, _, test_data, test_labels, _ = io.load_train_test_data(\n",
    "    train_dir, test_dir, mask_filter=masks_ext\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87b5e3",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Convert images to float32\n",
    "train_data = []\n",
    "for img in train_data:\n",
    "    train_data.append(img.astype(np.float32))\n",
    "# same as using list comprehension:\n",
    "# train_data = [img.astype(np.float32) for img in train_data]\n",
    "\n",
    "# Convert labels (masks) to int32\n",
    "train_labels = []\n",
    "for lbl in train_labels:\n",
    "    train_labels.append(lbl.astype(np.int32))\n",
    "# same as using list comprehension:\n",
    "# train_labels = [lbl.astype(np.int32) for lbl in train_labels]\n",
    "\n",
    "# Convert test images to float32 and labels to int32\n",
    "test_data = []\n",
    "for img in test_data:\n",
    "    test_data.append(img.astype(np.float32))\n",
    "# same as using list comprehension:\n",
    "# test_data = [img.astype(np.float32) for img in test_data]\n",
    "\n",
    "# Convert test labels (masks) to int32\n",
    "test_labels = []\n",
    "for lbl in test_labels:\n",
    "    test_labels.append(lbl.astype(np.int32))\n",
    "# same as using list comprehension:\n",
    "# test_labels = [lbl.astype(np.int32) for lbl in test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd4ccd",
   "metadata": {},
   "source": [
    "### <mark style=\"color: black; background-color: rgb(190,223,185); padding: 3px; border-radius: 5px;\">Init the Model</mark>\n",
    "\n",
    "Before we can train a new model, we need to initialize Cellpose with the correct settings.\n",
    "\n",
    "Here, we‚Äôll:\n",
    "- Specify the **model type** (e.g., \"cpsam\" (default), \"cyto\" or \"nuclei\") to use as a base model\n",
    "- Set the **channels** depending on how your images are structured (e.g., single-channel grayscale, or dual-channel with nuclei and cytoplasm)\n",
    "- Choose where to **save the model weights** during training\n",
    "\n",
    "> üí° Even when training a new model, Cellpose builds on a pre-trained backbone (unless you explicitly start from scratch). This helps it learn faster and perform better‚Äîespecially on small datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d52c1d",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Initialize the Cellpose model\n",
    "model = models.CellposeModel(gpu=use_gpu, model_type=\"cpsam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c583a4",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# run model on test images\n",
    "masks = model.eval(test_data, batch_size=32)[0]\n",
    "\n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print(f\"\\n>>> average precision at iou threshold 0.5 = {ap[:, 0].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5400c63d",
   "metadata": {},
   "source": [
    "## <mark style=\"color: black; background-color: rgb(127,196,125); padding: 3px; border-radius: 5px;\">Train New Model</mark>\n",
    "\n",
    "Now we‚Äôre ready to train! In this step, we‚Äôll tell Cellpose to:\n",
    "- Use the training images and masks\n",
    "- Save the trained model to your specified directory\n",
    "- Run for a defined number of **epochs** (iterations over the full dataset)\n",
    "\n",
    "You can also set other options like:\n",
    "- Learning rate\n",
    "- Batch size\n",
    "- Whether to use GPU\n",
    "\n",
    "> üí° Training time will vary depending on your dataset size and hardware. On Google Colab with a GPU, small datasets may train in just a few minutes.\n",
    "\n",
    "After training, the model weights will be saved and ready to use for predictions. We‚Äôll evaluate performance on the test data in the next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cae3f0",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "model_name = \"new_model\"\n",
    "\n",
    "# Training params\n",
    "n_epochs = 10\n",
    "learning_rate = 1e-5\n",
    "weight_decay = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# (not passing test data into function to speed up training)\n",
    "\n",
    "new_model_path, train_losses, test_losses = train.train_seg(\n",
    "    model.net,\n",
    "    train_data=train_data,\n",
    "    train_labels=train_labels,\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=n_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    nimg_per_epoch=max(2, len(train_data)),  # can change this\n",
    "    model_name=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fcc0a6",
   "metadata": {},
   "source": [
    "## <mark style=\"color: black; background-color: rgb(127,196,125); padding: 3px; border-radius: 5px;\">Evaluate on test data</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148eb39",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "model = models.CellposeModel(gpu=True, pretrained_model=new_model_path)\n",
    "\n",
    "# run model on test images\n",
    "masks = model.eval(test_data, batch_size=32)[0]\n",
    "\n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print(f\"\\n>>> average precision at iou threshold 0.5 = {ap[:, 0].mean():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
