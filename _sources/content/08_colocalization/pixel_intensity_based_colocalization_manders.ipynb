{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e296f4b",
   "metadata": {},
   "source": [
    "# Manders' Correlation Coefficients\n",
    "\n",
    "<div class=\"custom-button-row\">\n",
    "    <a \n",
    "        class=\"custom-button custom-download-button\" href=\"../../notebooks/08_colocalization/pixel_intensity_based_colocalization_manders.ipynb\" download>\n",
    "        <i class=\"fas fa-download\"></i> Download this Notebook\n",
    "    </a>\n",
    "    <a\n",
    "    class=\"custom-button custom-download-button\" href=\"https://colab.research.google.com/github/HMS-IAC/bobiac/blob/gh-pages/colab_notebooks/08_colocalization/pixel_intensity_based_colocalization_manders.ipynb\" target=\"_blank\">\n",
    "        <img class=\"button-icon\" src=\"../../_static/logo/icon-google-colab.svg\" alt=\"Open in Colab\">\n",
    "        Open in Colab\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /// script\n",
    "# requires-python = \">=3.12\"\n",
    "# dependencies = [\n",
    "#     \"matplotlib\",\n",
    "#     \"ndv[jupyter,vispy]\",\n",
    "#     \"scikit-image\",\n",
    "#     \"numpy\",\n",
    "#     \"scipy\",\n",
    "#     \"tifffile\",\n",
    "#     \"imagecodecs\",\n",
    "#     \"tqdm\",\n",
    "#     \"coloc_tools @ git+https://github.com/fdrgsp/coloc-tools.git\"\n",
    "# ]\n",
    "# ///"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc72aa",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "In this notebook, we will explore how to implement **Manders' Correlation Coefficients** in Python, a common method for quantifying colocalization based on pixel intensities.\n",
    "\n",
    "The images we will use for this section can be downloaded from the <a href=\"../../../_static/data/08_pixel_intensity_based_coloc.zip\" download> <i class=\"fas fa-download\"></i> Manders' & Pearson's Colocalization Dataset</a>.\n",
    "\n",
    "<p class=\"alert alert-warning\">\n",
    "   <strong>Note:</strong> This notebook aims to show how to practically implement these methods but does not aim to describe when to use this method. The images used have been selected to showcase the practical implementation of the methods.\n",
    "</p>\n",
    "\n",
    "<p class=\"alert alert-warning\">\n",
    "    <strong>Note:</strong> In this example, we will not perform any image processing steps before computing the Manders' Correlation Coefficients since the image provided has been corrected already. However, when conducting a real colocalization analysis, you should consider applying some image processing steps to clean the images before computing the Manders' Correlation Coefficients, such as background subtraction, flat-field correction, etc. \n",
    "</p>\n",
    "\n",
    "<p class=\"alert alert-info\">\n",
    "    <strong>Note:</strong> In this notebook, we will only use a single image pair for demonstration purposes. Often, Manders' coefficients should not be interpreted as absolute values in isolation. Instead, it's always recommended to consider them in the context of comparisons between different conditions, controls, treatments, or experimental groups. The relative changes and ratios between conditions are often more meaningful than the absolute coefficient values themselves.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1dd28d",
   "metadata": {},
   "source": [
    "## Manders' Correlation Coefficients\n",
    "\n",
    "Manders' correlation coefficients can be used to quantify the degree of colocalization between two channels (or images). These coefficients, M1 and M2, are calculated based on the pixel intensities of the two channels and for this reason, they are different from a simple area overlap.\n",
    "\n",
    "<div> <img src=\"https://raw.githubusercontent.com/HMS-IAC/bobiac/main/_static/images/coloc/manders_slide.png\" alt=\"manders\" width=\"800\"></div>\n",
    "\n",
    "**M1** measures the **fraction of channel 1 (**$R^{}$**) intensity that sits where channel 2 (**$G^{}$**) is present**:\n",
    "- **Numerator**: sum of channel 1 in every pixel (**$R_i^{}$**) where\n",
    "    - channel 2 is above the channel 2 threshold (**$G_i^{}$**), and\n",
    "    - channel 1 is above the channel 1 threshold (**$R_i^{}$**)(if you set one).\n",
    "- **Denominator**: sum of **$R_i^{}$** (channel 1) in every pixel where **$R_i^{}$** is above the **$R_i^{}$**-threshold.\n",
    "\n",
    "**M2** measures the **fraction of channel 2 (**$G^{}$**) intensity that sits where channel 1 (**$R^{}$**) is present**:\n",
    "- **Numerator**: sum of channel 2 in every pixel (**$G_i^{}$**) where\n",
    "\t1. channel 1 (**$R_i^{}$**) is above the channel 1 threshold (**$R_i^{}$**), and\n",
    "\t2. channel 2 (**$G_i^{}$**) is above the channel 2 threshold (**$G_i^{}$**) (if you set one).\n",
    "- **Denominator**: sum of channel 2 in every pixel (**$G_i^{}$**) where channel 2 (**$G_i^{}$**) is above the channel 2 threshold (**$G_i^{}$**).\n",
    "\n",
    "For this exercise, we will analyze an image of a HeLa cell stained with two fluorescent markers: **channel 1** labels **endosomes** and **channel 2** labels **lysosomes** (<a href=\"../../_static/data/08_pixel_intensity_based_coloc.zip\" download><i class=\"fas fa-download\"></i>Manders' & Pearson's Colocalization Dataset</a>.)\n",
    "\n",
    "From a biological perspective, lysosomes are typically found within or closely associated with endosomal compartments, while endosomes have a broader cellular distribution. Based on this biology, we expect:\n",
    "\n",
    "- **High M2 coefficient**: Most lysosomal signal should colocalize with endosomal regions\n",
    "- **Lower M1 coefficient**: Only a subset of endosomal signal should colocalize with lysosomes, since endosomes are more widely distributed throughout the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f616961",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724dea6",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ndv\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from coloc_tools import (\n",
    "    manders_image_rotation_test,\n",
    "    manders_image_rotation_test_plot,\n",
    "    manders_image_translation_randomization,\n",
    "    pca_auto_threshold,\n",
    ")\n",
    "from skimage.filters import threshold_otsu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef6900a",
   "metadata": {},
   "source": [
    "### Load and Visualize the Image\n",
    "\n",
    "Open and visualize (with ndv) the image named `cells_manders_14na.tif` from the <a href=\"../../_static/data/08_pixel_intensity_based_coloc.zip\" download><i class=\"fas fa-download\"></i> Manders' & Pearson's Colocalization Dataset</a>. This is a two-channel image where channel 1 has stained endosomes and channel 2 has stained lysosomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58157086",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Open the image\n",
    "img_path = \"../../_static/images/coloc/cells_manders_14na.tif\"\n",
    "img = tifffile.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca3d02",
   "metadata": {
    "tags": [
     "skip-execution",
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize the image\n",
    "ndv.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea13af",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "viewer = ndv.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013bc0d3",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.widget().children[1].snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98764c14",
   "metadata": {},
   "source": [
    "To compute Manders' Correlation Coefficients, we need **two separate images** (channels). \n",
    "\n",
    "What is the image shape? How do we split the channels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86327fbe",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Get image shape\n",
    "print(\"Image shape:\", img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9bf352",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Split the image into channels\n",
    "ch1 = img[0]\n",
    "ch2 = img[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc303e",
   "metadata": {},
   "source": [
    "### Calculate Numerators and Denominators for Manders' Correlation Coefficients\n",
    "\n",
    "The first and key step is to calculate **$R_i^{}$** and **$G_i^{}$** and thus to select which areas of each channel we want to consider for the colocalization analysis. This means we first need to **threshold each images to select only the pixels we want to consider**.\n",
    "\n",
    "It is therefore evident that Manders' Correlation Coefficients are **sensitive to thresholding**, the way you decide to threshold your images will have a large impact on the results.\n",
    "\n",
    "For this example, we will first use a simple Otsu thresholding method and later in the notebook we will explore a more automated way of selecting the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d3aa1",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Create binary masks based on thresholds\n",
    "image_1_mask = ch1 > threshold_otsu(ch1)\n",
    "image_2_mask = ch2 > threshold_otsu(ch2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0642f375",
   "metadata": {},
   "source": [
    "We can plot the raw data and the masks in a 2x2 subplot to visualize the results of the thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7526f6cb",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot raw data and masks in a 2x2 subplot\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "# Raw channel 1\n",
    "im1 = ax[0, 0].imshow(ch1)\n",
    "ax[0, 0].set_title(\"Channel 1 (Raw Data)\")\n",
    "ax[0, 0].axis(\"off\")\n",
    "plt.colorbar(im1, ax=ax[0, 0], fraction=0.045)\n",
    "# Raw channel 2\n",
    "im2 = ax[0, 1].imshow(ch2)\n",
    "ax[0, 1].set_title(\"Channel 2 (Raw Data)\")\n",
    "ax[0, 1].axis(\"off\")\n",
    "plt.colorbar(im2, ax=ax[0, 1], fraction=0.045)\n",
    "# Channel 1 mask\n",
    "ax[1, 0].imshow(image_1_mask)\n",
    "ax[1, 0].set_title(\"Channel 1 Mask\")\n",
    "ax[1, 0].axis(\"off\")\n",
    "# Channel 2 mask\n",
    "ax[1, 1].imshow(image_2_mask)\n",
    "ax[1, 1].set_title(\"Channel 2 Mask\")\n",
    "ax[1, 1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce32fb",
   "metadata": {},
   "source": [
    "Now that we have the mask for each channel, we can first **calculate the overlap mask** where both channels are above their respective thresholds, and then calculate **$R_i^{coloc}$** and **$G_i^{coloc}$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81202e9",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Get the overlap mask using a logical AND operation\n",
    "overlap_mask = image_1_mask & image_2_mask\n",
    "\n",
    "# Plot overlap mask\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(overlap_mask)\n",
    "plt.title(\"Overlap Mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3076eb",
   "metadata": {},
   "source": [
    "With the overlap mask, we can now calculate the **$R_i^{coloc}$** (*ch1_coloc*) and **$G_i^{coloc}$** (*ch2_coloc*) and the **numerator** for the Manders' Correlation Coefficients: **sum($R_i^{coloc}$)** and **sum($G_i^{coloc}$)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103976dd",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Numerator\n",
    "# Extract intensity from channel 1 only at pixels where both channels overlap\n",
    "ch1_coloc = ch1[overlap_mask]\n",
    "# Extract intensity from channel 2 only at pixels where both channels overlap\n",
    "ch2_coloc = ch2[overlap_mask]\n",
    "\n",
    "# Calculate the numerator for the Manders coefficients\n",
    "m1_numerator = np.sum(ch1_coloc)\n",
    "m2_numerator = np.sum(ch2_coloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce9ff23",
   "metadata": {},
   "source": [
    "We can now **calculate the denominator** for the Manders coefficients.\n",
    "<br>\n",
    "The denominator is the sum of the pixel intensities in the overlap mask for each channel above their respective thresholds: **sum($R_i^{}$)** and **sum($G_i^{}$)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085491bf",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Denominator\n",
    "# Calculate the sum of the intensities in channel 1 and channel 2 above their\n",
    "# respective thresholds\n",
    "ch1_tr = ch1[image_1_mask]\n",
    "ch2_tr = ch2[image_2_mask]\n",
    "m1_denominator = np.sum(ch1_tr)\n",
    "m2_denominator = np.sum(ch2_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eaf3fb",
   "metadata": {},
   "source": [
    "### Calculate Manders' Correlation Coefficients\n",
    "\n",
    "Now with both numerators and denominators calculated, we can compute the Manders coefficients M1 and M2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ccf24f",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate the Manders coefficients\n",
    "M1 = m1_numerator / m1_denominator\n",
    "M2 = m2_numerator / m2_denominator\n",
    "\n",
    "print(f\"Manders coefficient M1: {M1:.2f}\")\n",
    "print(f\"Manders coefficient M2: {M2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b68b8",
   "metadata": {},
   "source": [
    "With Otsu thresholding for both channels, we obtain:\n",
    "\n",
    "**M1=0.3496** and **M2=0.8975**\n",
    "\n",
    "- **M1** indicates that approximately **35%** (0.3496) of channel 1's intensity colocalizes with channel 2. This means that about one-third of channel 1's signal overlaps with areas where channel 2 is also present above threshold.\n",
    "\n",
    "- **M2** indicates that approximately **90%** (0.8975) of channel 2's intensity colocalizes with channel 1. This suggests that nearly all of channel 2's signal overlaps with areas where channel 1 is also present above threshold.\n",
    "\n",
    "This asymmetry (M1 ≠ M2) is common and tells us that **channel 2 is largely contained within areas where channel 1 is present**, but **channel 1 extends beyond the regions where channel 2 is found**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12baf806",
   "metadata": {},
   "source": [
    "**Bonus**: In the <a href=\"../../_static/data/08_pixel_intensity_based_coloc.zip\" download> <i class=\"fas fa-download\"></i> Manders' & Pearson's Colocalization Dataset</a> there is an image named `cells_manders_0.3na.tif`, the exact same image we just used nut acquired with a smaller numerical aperture (NA) of the objective lens.\n",
    "\n",
    "What do you think will happen to the Manders' coefficients if we use this image instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fedfc5",
   "metadata": {},
   "source": [
    "### Costes Auto-Threshold Method\n",
    "\n",
    "As mentioned above, the Mender's Correlation Coefficients are sensitive to thresholding, so the way you decide to threshold your images will have a large impact on the results.\n",
    "\n",
    "The [`pca_auto_threshold`](https://github.com/fdrgsp/coloc-tools/blob/fee98bb72ccdbffabdc0d4875a9d4fccd43cc8ab/src/coloc_tools/_costes_auto_threshold.py#L796) function from `coloc_tools` implements the [Costes auto-threshold method](https://pmc.ncbi.nlm.nih.gov/articles/PMC1304300/), which **automatically determines optimal threshold values for both channels**. \n",
    "\n",
    "The method works by finding threshold values where pixels *below* these thresholds show no statistical correlation (Pearson correlation coefficient ≈ 0). This approach helps objectively separate true signal from background noise.    The algorithm performs orthogonal regression (PCA) between the two channels to establish their relationship, then iteratively tests threshold pairs derived from this regression to identify the optimal separation point between signal and background.\n",
    "\n",
    "Of course, the Costes auto-threshold method has limitations and may not work in certain scenarios, including:\n",
    "- **Insufficient data**: When there are too few non-zero pixels (< 10) in either channel\n",
    "- **No linear relationship**: When channels show non-linear, multiple population, or no correlation patterns.\n",
    "- **Low variance**: When one or both channels have uniform or near-uniform intensities\n",
    "- **High background noise**: When noise dominates the signal relationship\n",
    "- **Limited dynamic range**: Narrow intensity ranges or saturated pixels\n",
    "\n",
    "In such cases, alternative thresholding methods (Otsu, manual, percentile-based) may be more appropriate.\n",
    "\n",
    "We can now try to compute and print the Manders' Correlation Coefficients using the Costes auto-threshold method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f792a0a6",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "source": [
    "### Calculate Manders' Coefficients with Costes Auto-Thresholds\n",
    "\n",
    "Calculate the Costes auto-thresholds for the two channels and print the thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c817765",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate Costes auto-thresholds for the two channels\n",
    "costes_thr_ch1, costes_thr_ch2, slope, intercept = pca_auto_threshold(ch1, ch2)\n",
    "print(\n",
    "    \"Costes thresholds:\\n\"\n",
    "    f\"Channel 1 = {costes_thr_ch1}\\n\"\n",
    "    f\"Channel 2 = {costes_thr_ch2}\\n\"\n",
    "    f\"Regression Eq: y = {slope:.4f} * x + {intercept:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122d27c6",
   "metadata": {},
   "source": [
    "**Bonus:** Plot also a scatter plot of the two channels with the linear regression line.\n",
    "\n",
    "Note that the `fiji_bisection_auto_threshold` function returns (in order) *Costes thresholds for channel 1*, *Costes thresholds for channel 2*, *slope* and *intercept* of the linear regression. We can use the slope and intercept to plot the linear regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc34d97",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# plot scatter plot of the two channels with thresholds\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(ch1.ravel(), ch2.ravel(), s=1, alpha=0.5)\n",
    "plt.axvline(costes_thr_ch1, color=\"green\", linestyle=\"--\", label=\"Threshold ch1\")\n",
    "plt.axhline(costes_thr_ch2, color=\"magenta\", linestyle=\"--\", label=\"Threshold ch2\")\n",
    "x_vals = np.unique(ch1.ravel())  # Get unique intensity values from ch1\n",
    "y_vals = slope * x_vals + intercept\n",
    "plt.plot(\n",
    "    x_vals, y_vals, color=\"k\", linestyle=\"--\", label=\"Regression line\", linewidth=2\n",
    ")\n",
    "plt.xlabel(\"Channel 1 Intensity\")\n",
    "plt.ylabel(\"Channel 2 Intensity\")\n",
    "plt.title(\"Costes Auto-Threshold Scatter Plot\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8604302",
   "metadata": {},
   "source": [
    "Now that we have the Costes thresholds, we can calculate the Manders' Correlation Coefficients using the Costes thresholds as we did for the Otsu thresholds.\n",
    "\n",
    "How do thresholds and mask images compare to the Otsu thresholds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b35b8",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Create binary masks based on thresholds\n",
    "image_1_mask = ch1 > costes_thr_ch1\n",
    "image_2_mask = ch2 > costes_thr_ch2\n",
    "\n",
    "# Plot raw data and masks in a 2x2 subplot\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "# Raw channel 1\n",
    "im1 = ax[0, 0].imshow(ch1)\n",
    "ax[0, 0].set_title(\"Channel 1 (Raw Data)\")\n",
    "ax[0, 0].axis(\"off\")\n",
    "plt.colorbar(im1, ax=ax[0, 0], fraction=0.045)\n",
    "# Raw channel 2\n",
    "im2 = ax[0, 1].imshow(ch2)\n",
    "ax[0, 1].set_title(\"Channel 2 (Raw Data)\")\n",
    "ax[0, 1].axis(\"off\")\n",
    "plt.colorbar(im2, ax=ax[0, 1], fraction=0.045)\n",
    "# Channel 1 mask\n",
    "ax[1, 0].imshow(image_1_mask)\n",
    "ax[1, 0].set_title(\"Channel 1 Mask\")\n",
    "ax[1, 0].axis(\"off\")\n",
    "# Channel 2 mask\n",
    "ax[1, 1].imshow(image_2_mask)\n",
    "ax[1, 1].set_title(\"Channel 2 Mask\")\n",
    "ax[1, 1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87520e4",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Get the overlap mask\n",
    "overlap_mask = image_1_mask & image_2_mask\n",
    "\n",
    "# Plot overlap mask\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(overlap_mask)\n",
    "plt.title(\"Overlap Mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdccc9b2",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Numerator\n",
    "# Extract intensity from channel 1 only at pixels where both channels overlap\n",
    "ch1_coloc = ch1[overlap_mask]\n",
    "# Extract intensity from channel 2 only at pixels where both channels overlap\n",
    "ch2_coloc = ch2[overlap_mask]\n",
    "\n",
    "# Calculate the numerator for the Manders coefficients\n",
    "m1_numerator = np.sum(ch1_coloc)\n",
    "m2_numerator = np.sum(ch2_coloc)\n",
    "\n",
    "# Denominator\n",
    "# Calculate the sum of the intensities in channel 1 and channel 2 above their\n",
    "# respective thresholds\n",
    "ch1_tr = ch1[image_1_mask]\n",
    "ch2_tr = ch2[image_2_mask]\n",
    "m1_denominator = np.sum(ch1_tr)\n",
    "m2_denominator = np.sum(ch2_tr)\n",
    "\n",
    "# Calculate the Manders coefficients\n",
    "M1 = m1_numerator / m1_denominator\n",
    "M2 = m2_numerator / m2_denominator\n",
    "\n",
    "print(f\"Manders coefficient M1: {M1:.2f}\")\n",
    "print(f\"Manders coefficient M2: {M2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bf50d3",
   "metadata": {},
   "source": [
    "### Image Rotation Test\n",
    "\n",
    "The **image rotation**, in this context, is a statistical method to validate colocalization significance. This method applies **rotations (90°, 180°, 270°) and flips (horizontal and vertical)** to one channel relative to the other, then recalculates the Manders' coefficients.\n",
    "\n",
    "**Note for Non-Square Images:** When working with non-square images, rotations by 90° and 270° would change the image dimensions (e.g., a 500×512 image becomes 512×500), making direct comparison impossible. To handle this, the function automatically pads non-square images to square dimensions with zeros before applying rotations, ensuring that all transformations maintain the same image size and allow valid statistical comparisons.\n",
    "\n",
    "The [manders_image_rotation_test](https://github.com/fdrgsp/coloc_tools/blob/8155900fd0140c6a84b79e3c76cf80c9611e5fbc/src/coloc_tools/_manders_image_rotation_test.py#L4) function provides an implementation of this method in Python. This function returns the Manders' coefficients, the rotated/flipped Manders' coefficients, and the p-values for both coefficients.\n",
    "\n",
    "A low `p-value` (e.g. 0.0001) means that none of the rotations/flips produced M1/M2 values as high as the observed values without translation, indicating that the observed colocalization is statistically significant: the probability of getting the observed colocalization by random chance is < 0.0001 (less than 0.01%).\n",
    "\n",
    "Let's run it on the two channels we have been working with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7b1beb",
   "metadata": {},
   "source": [
    "Calculate either the Otsu or Costes thresholds for the two channels and then run the image translation randomization test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b2b9a",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "thr_1, thr_2 = threshold_otsu(ch1), threshold_otsu(ch2)\n",
    "# thr_1, thr_2, _, _ = costes_auto_threshold(ch1, ch2)\n",
    "\n",
    "# Run the rotation test\n",
    "rotation_values = manders_image_rotation_test(ch1, ch2, thr_1, thr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c9f19",
   "metadata": {},
   "source": [
    "We can now print the results of the analysis: M1, M2, and their respective p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc06ea",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Extract results\n",
    "(\n",
    "    M1,\n",
    "    M2,\n",
    "    rot_m1_values,\n",
    "    rot_m2_values,\n",
    "    p_value_m1_rot,\n",
    "    p_value_m2_rot,\n",
    ") = rotation_values\n",
    "# Print results\n",
    "print(f\"M1: {M1:.2f}, p-value: {p_value_m1_rot:.4f}\")\n",
    "print(f\"M2: {M2:.2f}, p-value: {p_value_m2_rot:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473fc032",
   "metadata": {},
   "source": [
    "**Bonus:** We can also visualize the distribution of the random M1 and M2 values using a bar plot.\n",
    "\n",
    "To do this we can simply use the [`manders_image_rotation_test_plot`](https://github.com/fdrgsp/coloc-tools/blob/5a77363e4f6f7fcd8360870b314c3a33fa24a1df/src/coloc_tools/_manders_image_rotation_test.py#L137) function from `coloc_tools`, which takes the M1 and M2 values, the rotated M1 and M2 values, and the p-values for both coefficients as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "manders_image_rotation_test_plot(\n",
    "    M1,\n",
    "    M2,\n",
    "    rot_m1_values,\n",
    "    rot_m2_values,\n",
    "    p_value_m1_rot,\n",
    "    p_value_m2_rot,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be7657",
   "metadata": {},
   "source": [
    "### Image Translation Randomization Test\n",
    "\n",
    "The **image translation randomization** test is a statistical method used to **validate the significance of colocalization results**, particularly for Manders' coefficients. This method involves **randomly translating one channel relative to another and recalculating the Manders' coefficients** to create a distribution of values under the null hypothesis of no colocalization.\n",
    "\n",
    "**Note for Image Translations:** Unlike rotations, translations use wraparound shifting (via `np.roll()`) which preserves the original image dimensions regardless of image shape. When pixels are shifted beyond the image boundaries, they wrap around to the opposite side. This ensures that all pixel intensities are preserved and no padding is required, making this method suitable for images of any dimensions.\n",
    "\n",
    "The [manders_image_translation_randomization](https://github.com/fdrgsp/coloc_tools/blob/2ad1029f1ea5e5e0b0491dbd0b586b3233ce3415/src/coloc_tools/_manders_image_translation_test.py#L5) function from `coloc_tools` provides an implementation of this method in Python. This function returns the Manders' coefficients, the random Manders' coefficients, and the p-values for both coefficients.\n",
    "\n",
    "A low `p-value` (e.g. 0.0001) means that none of the `n` random translations (by default 1000) produced M1/M2 values as high as the observed values without translation, indicating that the observed colocalization is statistically significant: the probability of getting the observed colocalization by random chance is < 0.0001 (less than 0.01%).\n",
    "\n",
    "Let's run it on the two channels we have been working with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa84e570",
   "metadata": {},
   "source": [
    "Calculate either the Otsu or Costes thresholds for the two channels and then run the image translation randomization test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169660a4",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "thr_1, thr_2 = threshold_otsu(ch1), threshold_otsu(ch2)\n",
    "# thr_1, thr_2, _, _ = fiji_costes_auto_threshold(ch1, ch2)\n",
    "\n",
    "values = manders_image_translation_randomization(ch1, ch2, thr_1, thr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc1dd3",
   "metadata": {},
   "source": [
    "We can now print the results of the analysis: M1, M2, and their respective p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c24fa1",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "M1, M2, random_m1_values, random_m2_values, p_value_m1, p_value_m2 = values\n",
    "print(f\"M1: {M1:.4f}, p-value: {p_value_m1:.4f}\")\n",
    "print(f\"M2: {M2:.4f}, p-value: {p_value_m2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744c4eb5",
   "metadata": {},
   "source": [
    "**Bonus:** We can also visualize the distribution of the random M1 and M2 values using histograms. This will help us understand the significance of our observed values in the context of the random distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb4864",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# plot the distribution of random M1 and M2 values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(random_m1_values, bins=50, color=\"magenta\", alpha=0.7, label=\"Random M1\")\n",
    "plt.axvline(M1, color=\"k\", linestyle=\"--\", label=\"Observed M1\")\n",
    "plt.xlabel(\"M1 Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Random M1 Values\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(random_m2_values, bins=50, color=\"green\", alpha=0.7, label=\"Random M2\")\n",
    "plt.axvline(M2, color=\"k\", linestyle=\"--\", label=\"Observed M2\")\n",
    "plt.xlabel(\"M2 Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Random M2 Values\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc21c1a",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "The Python implementation for calculating Manders' Correlation Coefficients is straightforward and concise, as demonstrated in the code below.\n",
    "\n",
    "```python\n",
    "# Create binary mask for channel 1 & 2 using a thresholding method of choice\n",
    "threshold_ch1, threshold_ch2 = threshold_method(ch1, ch2)\n",
    "image_1_mask = ch1 > threshold_ch1\n",
    "image_2_mask = ch2 > threshold_ch2\n",
    "\n",
    "# Find pixels that are above threshold in both channels\n",
    "overlap_mask = image_1_mask & image_2_mask\n",
    "\n",
    "# Extract channel 1 & 2 intensities only from overlapping regions\n",
    "ch1_coloc = ch1[overlap_mask]\n",
    "ch2_coloc = ch2[overlap_mask]\n",
    "\n",
    "# Extract all channel 1 & 2 intensities above threshold\n",
    "ch1_tr = ch1[image_1_mask]\n",
    "ch2_tr = ch2[image_2_mask]\n",
    "\n",
    "# Calculate total intensity of channel 1 & 2 above threshold\n",
    "sum_ch1_tr = np.sum(ch1_tr)\n",
    "sum_ch2_tr = np.sum(ch2_tr)\n",
    "\n",
    "# M1: fraction of channel 1 intensity that colocalizes with channel 2\n",
    "M1 = np.sum(ch1_coloc) / sum_ch1_tr\n",
    "# M2: fraction of channel 2 intensity that colocalizes with channel 1\n",
    "M2 = np.sum(ch2_coloc) / sum_ch2_tr\n",
    "```\n",
    "\n",
    "**Key Considerations for Manders' Correlation Analysis:**\n",
    "\n",
    "1. **Threshold Sensitivity**: Manders' coefficients are **highly sensitive to thresholding methods**. The choice of thresholding strategy will significantly impact your results, making careful threshold selection essential for accurate colocalization analysis. Consider using:\n",
    "   - **Automated thresholding methods** (like Costes auto-threshold): these are fully automated and don't require you to select or tune any parameters\n",
    "   - **Threshold calculation algorithms** (like Otsu, Li, Triangle, Yen, etc.): these automatically calculate a threshold value, but you need to choose which algorithm to use based on your image characteristics and how the resulting threshold looks\n",
    "   - **Consistent thresholding**: use the same thresholding approach across experimental conditions\n",
    "\n",
    "2. **Background Considerations**: sometimes it is necessary to apply appropriate image preprocessing steps before calculating Manders' coefficients such as Background subtraction to remove non-specific signal or Flat-field correction to account for illumination variations.\n",
    "\n",
    "3. **Statistical Validation**: always validate your results using statistical tests such as the image rotation test or the image translation randomization test demonstrated above. This helps assess whether observed colocalization is statistically significant or could have occurred by chance.\n",
    "\n",
    "4. **Comparative Analysis**: Manders' coefficients should not be interpreted as absolute values in isolation. Instead, consider them in the context of:\n",
    "   - Comparisons between different experimental conditions\n",
    "   - Control vs. treatment groups\n",
    "   - Different time points or developmental stages\n",
    "   - Relative changes between conditions are often more meaningful than absolute values\n",
    "\n",
    "5. **Asymmetry Interpretation**: remember that M1 ≠ M2 is common and biologically meaningful.\n",
    "   - **M1**: Fraction of channel 1 intensity that overlaps with channel 2\n",
    "   - **M2**: Fraction of channel 2 intensity that overlaps with channel 1\n",
    "   - This asymmetry can reveal important biological relationships between the labeled structures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
